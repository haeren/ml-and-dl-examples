{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "503020210073_Hakan_Alp_Eren_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgBMYvTwsH-v"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "tanhDerivative = lambda x : 1 - np.tanh(x)**2\n",
        "\n",
        "\"\"\"\n",
        "Function to get feature vectors and numeric labels (-1 or 1) of the images in the given path\n",
        "Only images belonging to the two given classes will be returned\n",
        "Params:\n",
        "    folderPath (str): Path of the subset (train/test)\n",
        "    class1 (str): Folder name of the class to be numerically labeled as -1\n",
        "    class2 (str): Folder name of the class to be numerically labeled as 1\n",
        "Returns:\n",
        "    inputs (list), t (list): Lists of feature vectors and numeric labels\n",
        "\"\"\"\n",
        "def readDataSet(folderPath, class1, class2):\n",
        "    inputs = []\n",
        "    t = []\n",
        "    for root, dirs, files in os.walk(folderPath):\n",
        "        for file in files:\n",
        "            if file.endswith('.jpg'):\n",
        "                filePath = os.path.join(root, file)\n",
        "                pathParts = Path(root).parts\n",
        "                className = pathParts[-1]\n",
        "                if className != class1 and className != class2:\n",
        "                    continue\n",
        "                img = cv2.imread(filePath)\n",
        "                imgResized = cv2.resize(img, dsize=(64,64), interpolation=cv2.INTER_CUBIC)\n",
        "                imgVector = imgResized.flatten()\n",
        "                inputs.append(imgVector)\n",
        "                if className == class1:\n",
        "                    t.append(-1) # Class1 is labeled as -1 because the tanh activation function gives output in range [-1,1]\n",
        "                elif className == class2:\n",
        "                    t.append(1)\n",
        "    return inputs, t\n",
        "\n",
        "\"\"\"\n",
        "Function to train perceptron with tanh activation function\n",
        "Params:\n",
        "    inputs (list): Feature vectors of train samples\n",
        "    t (list): Numeric labels of train samples\n",
        "    weights (numpy.array): Weights with initial random small values\n",
        "    rho (float): Learning rate\n",
        "    iterNo (int): Number of iterations\n",
        "Returns:\n",
        "    weights (numpy.array): Weights after the training\n",
        "\"\"\"\n",
        "def trainPerceptron(inputs, t, weights, rho, iterNo):\n",
        "    gradient = np.zeros(len(weights)) # May be removed, new values will be assigned to the gradient in the loop\n",
        "    \n",
        "    for iteration in range(iterNo):\n",
        "        for index, x in enumerate(inputs):\n",
        "            summation = np.matmul(np.transpose(weights), x) # Feed forward: Calculate the sum\n",
        "            y = np.tanh(summation) # Feed forward: Activation function\n",
        "            error = t[index] - y # Feed backward: Loss computation\n",
        "            gradient = rho * error * tanhDerivative(y) * x # Feed backward: Calculate the gradient\n",
        "            weights = weights + gradient # Feed backward: Update the weights\n",
        "    return weights\n",
        "\n",
        "\"\"\"\n",
        "Function to test perceptron with tanh activation function\n",
        "Params:\n",
        "    sampleTest (list): Feature vectors of test samples\n",
        "    weights (numpy.array): Trained weights\n",
        "Returns:\n",
        "    predictions (list): Predicted labels\n",
        "\"\"\"\n",
        "def testPerceptron(sampleTest, weights):\n",
        "    predictions = []\n",
        "    \n",
        "    for x in sampleTest:\n",
        "        summation = np.matmul(np.transpose(weights), x) # Feed forward: Calculate the sum\n",
        "        y = np.tanh(summation) # Feed forward: Activation function\n",
        "        predictions.append(y)\n",
        "    return predictions\n",
        "            \n",
        "# Train and test paths\n",
        "trainPath = r'/content/drive/MyDrive/YuksekLisans/DLAPP/HW3/CaltechTinySplit/train'\n",
        "valPath = r'/content/drive/MyDrive/YuksekLisans/DLAPP/HW3/CaltechTinySplit/val'\n",
        "testPath = r'/content/drive/MyDrive/YuksekLisans/DLAPP/HW3/CaltechTinySplit/test'\n",
        "\n",
        "# Feature vectors and labels for train and test\n",
        "trainX, trainY = readDataSet(trainPath, 'cannon', 'cellphone')\n",
        "valX, valY = readDataSet(valPath, 'cannon', 'cellphone')\n",
        "testX, testY = readDataSet(testPath, 'cannon', 'cellphone')\n",
        "\n",
        "# Bias term\n",
        "for i in range(len(trainX)):\n",
        "    trainX[i] = np.append(trainX[i], 1)\n",
        "\n",
        "# Bias term\n",
        "for i in range(len(valX)):\n",
        "    valX[i] = np.append(valX[i], 1)\n",
        "\n",
        "# Bias term    \n",
        "for i in range(len(testX)):\n",
        "    testX[i] = np.append(testX[i], 1)\n",
        "\n",
        "# Initialized weights with a random small value\n",
        "weights = np.zeros(len(trainX[0]))\n",
        "for i in range(len(weights)):\n",
        "    weights[i] = random.randint(1,9) * 10**-2\n",
        "\n",
        "trainX, trainY = shuffle(trainX, trainY) # Shuffle the train data\n",
        "weights = trainPerceptron(trainX, trainY, weights, 0.001, 1000) # Train\n",
        "np.save('weights.npy', weights) # Saving weights to file\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFXsK_C5P9DU",
        "outputId": "39df3b12-4b32-4dc2-be0f-1d6e45c27194"
      },
      "source": [
        "weights = np.load('weights.npy') # Loading weights from file\n",
        "\n",
        "valPredictions = testPerceptron(valX, weights) # Predicting the validation set\n",
        "\n",
        "# Compare the actual validation labels with the predictions\n",
        "print('Actual\\tPred.\\tComparison')\n",
        "for i in range(len(valPredictions)):\n",
        "    print('{}\\t{}\\t{}'.format(valY[i], valPredictions[i], valY[i]==valPredictions[i]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual\tPred.\tComparison\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ewH4cWtQDCB",
        "outputId": "569c292a-36bf-448b-fd67-21f4f767ca1f"
      },
      "source": [
        "weights = np.load('weights.npy') # Loading weights from file\n",
        "\n",
        "testPredictions = testPerceptron(testX, weights) # Predicting the test set\n",
        "\n",
        "# Compare the actual test labels with the predictions\n",
        "print('Actual\\tPred.\\tComparison')\n",
        "for i in range(len(testPredictions)):\n",
        "    print('{}\\t{}\\t{}'.format(testY[i], testPredictions[i], testY[i]==testPredictions[i]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual\tPred.\tComparison\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "1\t1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n",
            "-1\t-1.0\tTrue\n"
          ]
        }
      ]
    }
  ]
}